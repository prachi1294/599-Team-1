{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNyRSLOYCFKw0cZTuA6XEi9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prachi1294/599-Team-1/blob/main/project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EauhycVpwwuj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ea96b24-3c3b-4ed9-d867-d0d41f493000"
      },
      "source": [
        "import requests\n",
        "import regex as re\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk import clean_html\n",
        "import operator\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "\n",
        "from IPython.display import Javascript\n",
        "def resize_colab_cell():\n",
        "  display(Javascript('google.colab.output.setIframeHeight(0, true, {maxHeight: 5000})'))\n",
        "get_ipython().events.register('pre_run_cell', resize_colab_cell)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGV2HMz-2BAW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "44ae9468-5602-439c-dd32-8188da4bdc54"
      },
      "source": [
        "def read_books(url):\n",
        "    r = requests.get(url)\n",
        "    r.encoding = r.apparent_encoding\n",
        "\n",
        "    # What comes back includes headers and other HTTP stuff, get just the body of the response\n",
        "    t = r.text\n",
        "    return t\n",
        "\n",
        "#save all the books\n",
        "the_extra_ordinary_adv_lupin = 'https://www.gutenberg.org/files/6133/6133-0.txt'\n",
        "arsene_lupin = 'https://www.gutenberg.org/cache/epub/4014/pg4014.txt'\n",
        "lupin_vs_herlock_sholmes = 'https://www.gutenberg.org/files/40203/40203-0.txt'\n",
        "the_hollow_needle = 'https://www.gutenberg.org/files/4017/4017-0.txt'\n",
        "the_confession_of_lupin = 'https://www.gutenberg.org/cache/epub/28093/pg28093.txt'\n",
        "\n",
        "\n",
        "#read all the books one by one\n",
        "book1 = read_books(the_extra_ordinary_adv_lupin)\n",
        "book2 = read_books(arsene_lupin)\n",
        "book3 = read_books(lupin_vs_herlock_sholmes)\n",
        "book4 = read_books(the_hollow_needle)\n",
        "book5 = read_books(the_confession_of_lupin)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 5000})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YbkyrA-AtyS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "71a85320-b905-43c3-a436-4dc0b6ab9675"
      },
      "source": [
        "stop_words = nltk.corpus.stopwords.words('english') + [\n",
        " 'ut', '\\'re','.', ',', '--', '\\'s', '?','â\\x80\\x9ci', ')', '(', ':', '\\'',\n",
        " '\\\"', '-', '}', '{', '\\\"','&', '|', u'\\u2014', '' ]\n",
        "\n",
        "\n",
        "\n",
        " # We most likely would like to remove html markup\n",
        "def cleanHtml (html):\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    return soup .get_text()\n",
        "\n",
        "\n",
        "def cleanWord (w):\n",
        "    # r in r'[.,\"\\']' tells to treat \\ as a regular character \n",
        "    # but we need to escape ' with \\'\n",
        "    # any character between the brackets [] is to be removed \n",
        "    #we need to get rid of this: â\\x80\\x9ci\n",
        "    #wn = re.sub('â\\x80\\x9ci', '\\\"', w)\n",
        "    wn = re.sub('[,\"\\.\\'&\\|:@>*;/=?!‘’“”]', \"\", w)\n",
        "    # get rid of numbers\n",
        "    wnum = re.sub('^[0-9\\.]*$', \"\", wn)\n",
        "    #get rid of quotes\n",
        "    #wq = wnum.replace('\"','')\n",
        "    return wnum\n",
        "\n",
        "def clean_words (text):\n",
        "    \n",
        "    # Now clean\n",
        "    # remove html markup\n",
        "    t = cleanHtml (text) .lower()\n",
        "    \n",
        "    # split string into an array of words using any sequence of spaces \"\\s+\" \n",
        "    wds = re .split('\\s+',t)\n",
        "    # remove periods, commas, etc stuck to the edges of words\n",
        "    for i in range(len(wds)):\n",
        "        wds [i] = cleanWord (wds [i])\n",
        "    \n",
        "    \n",
        "    filtered_words = [word for word in wds if word not in stop_words]\n",
        "    \n",
        "    return filtered_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 5000})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v81myY6xOugQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "47a2b171-aca7-43ba-8f7a-c19dbf430ed9"
      },
      "source": [
        "(book1_text) =  clean_words (book1)\n",
        "print(book1_text[331:400])\n",
        "\n",
        "#sp_quote = book1[2000:4000]\n",
        "#print(sp_quote)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 5000})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['r', 'moment', 'terrible', 'flash', 'lightning', 'rent', 'stormy', 'skies', 'electric', 'waves', 'interrupted', 'remainder', 'dispatch', 'never', 'reached', 'us', 'name', 'arsène', 'lupin', 'concealing', 'knew', 'initial', 'news', 'character', 'doubt', 'secret', 'would', 'carefully', 'guarded', 'telegraphic', 'operator', 'well', 'officers', 'vessel', 'one', 'events', 'calculated', 'escape', 'rigorous', 'discretion', 'day', 'one', 'knew', 'incident', 'became', 'matter', 'current', 'gossip', 'every', 'passenger', 'aware', 'famous', 'arsène', 'lupin', 'hiding', 'midst', 'arsène', 'lupin', 'midst', 'irresponsible', 'burglar', 'whose', 'exploits', 'narrated', 'newspapers', 'past', 'months', 'mysterious', 'individual']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evlPqbwEyDLF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}